# Josh Martin, worked with Federico and Pat

from matplotlib import pyplot as plt
import pandas as pd
import numpy as np
import scipy.cluster.hierarchy as sch
from matplotlib.pyplot import legend
from sklearn.cluster import AgglomerativeClustering

# Extracting the data from the csv file
data = pd.read_csv("input.csv", delimiter=';', header=None, decimal=",")
number_cluster = data.loc[0,0]
elements = data.loc[1,0]
print(data)

array = data.to_numpy()
X = array[2:20,:]
num_elem = len(X)+1
area = np.pi*3

#endregion

#region Perform scatter plot of data array X
labels = range(1,num_elem)
plt.figure(figsize=(11,8))
plt.style.use('seaborn')
plt.subplots_adjust(bottom=0.1)
plt.scatter(X[:,0],X[:,1], s=area, label='Data plots')

plt.title('Scatter Plot')
plt.xlabel('X coords')
plt.ylabel('Y coords')

for label, x, y in zip(labels, X[:, 0], X[:, 1]):
    l1 = plt.annotate(
        label,
        xy=(x,y),xytext=(-3,3),
        textcoords='offset points', ha='right', va='bottom')


plt.legend(loc=1, shadow=bool)
plt.show()

# Aggiomerative hierarchical algorithm & dendrogram

clustering = AgglomerativeClustering(n_clusters = int(number_cluster), affinity = 'euclidean', linkage ='ward')
clustering.fit_predict(X)
number = clustering.labels_
number = number+1
print(number)


linked = sch.linkage(X, method='ward')
labelList = range(1,num_elem)
plt.figure(figsize=(10,7))
plt.title('Input data for Dendogram')
plt.xlabel('scatter plot points')
plt.ylabel('Euclidean Distance')

sch.dendrogram(linked,
               orientation='top',
               distance_sort='descending',
               color_threshold=1,
               labels=labelList,


               show_leaf_counts=True)


# def c(group, param1, param2):
#     pass
#
#
# legend("topleft",
#        legend = c("group 1", "group 2", "group 3")
#        col: object= c("cyan", "red", "magneta")
#         )


plt.show()
